---
title: "Project: CATE"
subtitle: "Data Exploration (SMMNR related)"
date: 2018-08-10  
output:
  word_document: default
  pdf_document: default
  html_document:
  code_folding: hide
  df_print: paged
---

# Data Exploration Topics

* Categories reduction
* Derived variables
* Missing values and outliers
* Subgroups, patterns and trends
* Covariations (relationships between pairs of attributes)
    - distribution of a continuous variable broken down by a categorical variable
    - between categorical variables
    - between two continuous variables
* Correlations (numerical variables)

```{r, echo = FALSE}
# ====================== Libraries ================
library(readxl)
library(tidyverse)
library(hexbin)
# ====================== Parameters ==============
rel_fpath  <- "./data/"    # relative directory where original data is stored
filename ='A5E01283425_30062016_25072016' # file name of the original data 
filename2 ='A5E02758387_01062016_25072016' # file name of the original data
filename3 ='A5E02758387_11072016_15082016' # file name of the original data
filename4 ='A5E31281377_15062016_11072016_BGmitwenigenFehlern' # file name of the original data
filename5 ='A5E32692783_25072016_15082016' # file name of the original data
filename6 ='BD_CIB_DAC-A5E33212840_01062016_01072016' # file name of the original data
filename7 ='CIB_DAC-A5E33212840_01072016_25072016' # file name of the original data

endung ='.csv'            # file extension of the original data
rel_fpath_output <- "./data/" # relative directory where outputs are stored
outputcsv  <- "./output/clean_4_modelling_with_R.csv"

Read_Fresh_from_File <- F  # Set to TRUE for first run to fill var rawframe
                           # clean dat frame, set to FALSE for initial data understanding
options(scipen=999)        # suppress exponential form of print output format
shortnames <- TRUE         # if T change to short variable names is desired
scatterplot <- FALSE       # it T do scatterplot
basic_tranform <- T        # do basic feature transformations
# ====================== Sources ===============
source(file = "Functions_data_exploration.R")
```
#2. D a t a   U n d e r s t a n d i n g
  
##2.1 Collect Initial Data

Routines:  
Read from data sources from "rel_fpath"!  
Read description and configuration file from "rel_fpath"!  
Save data as RDS file format 

###2.1.1 Collect ICT measurement Data

```{r, echo = FALSE}
# ====================== R e a d   d a t a ============== alternative
library(writexl)
if (Read_Fresh_from_File)  {
  print("reading file.... ")
  # --- read excel ----
  if (endung == ".xlsx")   {
     rawframe <- read_xlsx (path = paste0(rel_fpath, filename, endung ), guess_max=100000)
     warnings()
  } else
  {  #--- read other formats ---
  rawframe <- read_data_csv(data_file_name = paste0(rel_fpath, filename, endung))
  rawframe2 <- read_data_csv(data_file_name = paste0(rel_fpath, filename2, endung))
  rawframe3 <- read_data_csv(data_file_name = paste0(rel_fpath, filename3, endung))
  rawframe4 <- read_data_csv(data_file_name = paste0(rel_fpath, filename4, endung))
  rawframe5 <- read_data_csv(data_file_name = paste0(rel_fpath, filename5, endung))
  rawframe6 <- read_data_csv(data_file_name = paste0(rel_fpath, filename6, endung))
  rawframe7 <- read_data_csv(data_file_name = paste0(rel_fpath, filename7, endung))
  }

  saveRDS(rawframe, file = paste(rel_fpath_output , filename, ".rData"))
  saveRDS(rawframe2, file = paste(rel_fpath_output , filename2, ".rData2"))
  saveRDS(rawframe3, file = paste(rel_fpath_output , filename3, ".rData3"))
  saveRDS(rawframe4, file = paste(rel_fpath_output , filename4, ".rData4"))
  saveRDS(rawframe5, file = paste(rel_fpath_output , filename5, ".rData5"))
  saveRDS(rawframe6, file = paste(rel_fpath_output , filename6, ".rData6"))
  saveRDS(rawframe7, file = paste(rel_fpath_output , filename7, ".rData7"))
  print("...Data saved in RData file")
} else { # Read_Fresh_from_File gleich FALSE
  rawframe <- readRDS(file = paste(rel_fpath_output , filename, ".rData"))
  rawframe2 <- readRDS(file = paste(rel_fpath_output , filename2, ".rData2"))
  rawframe3 <- readRDS(file = paste(rel_fpath_output , filename3, ".rData3"))
  rawframe4 <- readRDS(file = paste(rel_fpath_output , filename4, ".rData4"))
  rawframe5 <- readRDS(file = paste(rel_fpath_output , filename5, ".rData5"))
  rawframe6 <- readRDS(file = paste(rel_fpath_output , filename6, ".rData6"))
  rawframe7 <- readRDS(file = paste(rel_fpath_output , filename7, ".rData7"))
}
#--- create / read data control file ---
if (file.exists(path = paste0(rel_fpath, filename, '_data_control.xlsx')))
  data_control_file <-  paste0(rel_fpath, filename, '_data_control.xlsx') else
    data_control_file <- paste0(rel_fpath, 'data_control_template.xlsx')
datadesc <- read_datadesc(data_control_file)
  
# initial exclusion of not relevant variables according to Data Description entry in column Clean Data Frame
rawframe <- rawframe[ ,datadesc$`Clean Data Frame`!="exclude"]  
rawframe2 <- rawframe2[ ,datadesc$`Clean Data Frame`!="exclude"]  
rawframe3 <- rawframe3[ ,datadesc$`Clean Data Frame`!="exclude"]  
rawframe4 <- rawframe4[ ,datadesc$`Clean Data Frame`!="exclude"]  
rawframe5 <- rawframe5[ ,datadesc$`Clean Data Frame`!="exclude"]  
rawframe6 <- rawframe6[ ,datadesc$`Clean Data Frame`!="exclude"]  
rawframe7 <- rawframe7[ ,datadesc$`Clean Data Frame`!="exclude"]  

# write control file if not present
if (!file.exists(path = paste0(rel_fpath, filename, '_data_control.xlsx')))  {
  datadesc[1:length(names(rawframe)), 1] <-  names(rawframe)
  writexl::write_xlsx(datadesc, path = paste0(rel_fpath, filename, '_data_control.xlsx'))
}

```

Generation of data snapshot for generating Tableau input data.
Pulls each 20.000 single measurements from each ICT file and stores it in csv file
```{r, echo = FALSE}
rawframesnap <- rawframe[1:20000, ] %>% rbind(rawframe2[1:20000, ]) %>% rbind(rawframe3[1:20000, ]) %>% rbind(rawframe4[1:20000, ]) %>% rbind(rawframe5[1:20000, ]) %>% rbind(rawframe6[1:20000, ]) %>% rbind(rawframe7[1:20000, ]) 

#sorting - eases further exploration
rawframesnap <- rawframesnap %>% arrange(SPLATZNR, DTDATUM, NORDER)
#df_num$`Total Customer Price (EUR)` <- log(df_num$`Total Customer Price (EUR)`)
rawframesnap <- rawframesnap[rawframesnap$SEINHEIT != 'OE' ,]
write.table(rawframesnap,       # write resulting data into CSV file with tabstops
            file=paste0(rel_fpath, "raw_data_snap", endung),
            sep=";", quote=FALSE, row.names=FALSE, dec=",") 

```

Remove duplicate measurements, generate one combined rawframe for ICT measurements
```{r, echo = FALSE}
# check for double measurements - 258 cycles of two A5E02758387 - files
cat("check for double measurements - duplicated measurement cycles (SFILENR) of two A5E02758387 - files: ", 
sum(duplicated(c(unique(rawframe$SFILENAME), unique(rawframe2$SFILENAME), unique(rawframe3$SFILENAME), unique(rawframe4$SFILENAME), unique(rawframe5$SFILENAME), unique(rawframe6$SFILENAME), unique(rawframe7$SFILENAME)))) 
, "\n")
#sum(duplicated(c(rawframe2$NTDID, rawframe3$NTDID))) # 198380

#combine to one huge frame
rawframe <- rawframe %>% rbind(rawframe2) %>% rbind(rawframe3) %>% rbind(rawframe4) %>% rbind(rawframe5) %>% rbind(rawframe6) %>% rbind(rawframe7) 
remove(rawframe2, rawframe3, rawframe4, rawframe5, rawframe6, rawframe7)
# remove duplicated measurements
cat("removed duplicated single measurements (NTDID): ", 
sum(duplicated(rawframe$NTDID)) # 198380
, "\n")
rawframe <- rawframe[duplicated(rawframe$NTDID)=="FALSE", ]

#sorting - eases further exploration
rawframe <- rawframe %>% arrange(SPLATZNR, DTDATUM, NORDER)

#basic transformations - datenspezifisch!
if (basic_tranform) {
  #df_num$`Total Customer Price (EUR)` <- log(df_num$`Total Customer Price (EUR)`)
  rawframe <- rawframe[rawframe$SEINHEIT != 'OE' ,]
}

cat("In total", nrow(rawframe), "single measurement points (NTDID) after removing Soll-Istwerte lines\n\n")  
```
###2.1.2 Collect Q Data

```{r, echo = FALSE}
q_daten <- read_delim("data/DPMI_Fehler_alle_alle_201606_bis_201608_31.07.2018_adapt.csv", 
    ";", escape_double = FALSE, col_types = cols(DATUM = col_datetime(format = "%d.%m.%Y %H:%M")),
    locale = locale(encoding = "ISO-8859-1"), 
    trim_ws = TRUE)
# remove Prüfstufe Gerät, subsequently delete empty columns
#q_daten <- q_daten[q_daten$PRUEFSTUFE != 'G', ]
#q_daten <- q_daten[, 1:15]

# remove duplicates in Q Data: 
cat("remove duplicates in Q Data: ", sum(duplicated(q_daten)), "rows \n")  
q_daten <- q_daten[duplicated(q_daten)=="FALSE", ]

# remove double entries of FID - first approach - of course information is lost - future: provide at least removed marker or move up as additional features
q_daten <- q_daten[duplicated(q_daten$FID)=="FALSE", ]
cat(nrow(q_daten), "rows remaining\n")  


Error_mapping <- data.frame(BEFUND = c("B000", "B100", "V110", "V120", "V210", "V230"),
  BEFUND_clean = c("Pseudo Error", "Offene Lötstelle", "Offene Lötstelle", "Falsches Bauteil", "Offene Lötstelle", "Kurzschluß"))

q_daten <- left_join(q_daten, Error_mapping)

```
###2.1.3 Collect Localisation info

```{r}
#locinfo <- extract_location("data/")   # #A5E01283425
#locinfo$SARTIKELNR <- "A5E01283425"
#locinfo <- select(locinfo, SARTIKELNR, everything())

locinfo2 <- extract_location("data/A5E02758365A-02.pcf")   # #A5E02758387
locinfo2$SARTIKELNR <- "A5E02758387"
locinfo2 <- select(locinfo2, SARTIKELNR, everything())

locinfo4 <- extract_location("data/A5E31281435-AC.pcf")   # #A5E31281377
locinfo4$SARTIKELNR <- "A5E31281377"
locinfo4 <- select(locinfo4, SARTIKELNR, everything())

locinfo5 <- extract_location("data/A5E01283404A-02.pcf")   # #A5E32692783
locinfo5$SARTIKELNR <- "A5E32692783"
locinfo5 <- select(locinfo5, SARTIKELNR, everything())

locinfo6 <- extract_location("data/A5E02144933A-02.pcf")   # #A5E33212840
locinfo6$SARTIKELNR <- "A5E33212840"
locinfo6 <- select(locinfo6, SARTIKELNR, everything())

locinfo <- locinfo2 %>% bind_rows(locinfo4) %>% bind_rows(locinfo5) %>% bind_rows(locinfo6)
remove(locinfo2, locinfo4, locinfo5, locinfo6)
```

Extraction of SMMNR
```{r}
SMMNR_table <- rawframe %>% select(SARTIKELNR, SCOMB_PL, SMMNR, DTU, DTO, SEINHEIT) %>% unique()  # DTU DTO reinnhemne erhöht die verschiedene entries uaf 6tsd..
SMMNR_table$SMMNR_clean <- SMMNR_table$SMMNR

for(i in 1:length(SMMNR_table$SMMNR_clean)) {
  underscore1 <- regexpr("_", SMMNR_table$SMMNR_clean[i]) # position of first "_"
  underscore2 <- regexpr("_", substring(SMMNR_table$SMMNR_clean[i], underscore1+1, nchar(SMMNR_table$SMMNR_clean[i]))) # position of second "_"
  if ((underscore1 > 0) & (underscore2 > 0)) {
    SMMNR_table$SMMNR_clean[i] <- substring(SMMNR_table$SMMNR_clean[i], underscore1+1, underscore1+underscore2-1) # delete string before first "_"
  }
  underscore <- regexpr("_", SMMNR_table$SMMNR_clean[i]) # position of next "_"
  if (underscore > 0)  {
    SMMNR_table$SMMNR_clean[i] <- substring(SMMNR_table$SMMNR_clean[i], 1, underscore-1) #cut string from next "_"
  }
  hyphen <- regexpr("-", SMMNR_table$SMMNR_clean[i]) # position of next "-"  
  if (hyphen > 0)  {
    SMMNR_table$SMMNR_clean[i] <- substring(SMMNR_table$SMMNR_clean[i], 1, hyphen-1) #cut string from next "-"
    }  
}

SMMNR_table <- left_join (SMMNR_table, locinfo)

plot(SMMNR_table$X_loc, SMMNR_table$Y_loc)
write.table(SMMNR_table,       # write resulting data into CSV file with tabstops
            file=paste0(rel_fpath, "SMMNR_loc_info", endung),
            sep=";", quote=FALSE, row.names=FALSE, dec=",") 
ggplot(SMMNR_table) +
  geom_point(mapping = aes(x = X_loc, y = Y_loc)) +
  facet_wrap(~SARTIKELNR, ncol = 2, scales = "free")

```

##2.2 Feature Engineering on rawframe level   

Routines:  
Add delta NTDID_rel
Add violation id = delta of NTDID (NORDER wo gaps)

```{r, echo = FALSE}
SFILENR_help <- rawframe %>% group_by(SFILENAME) %>% summarize(SARTIKELNR=unique(SARTIKELNR), NTDID_rel = NTDID[1])
rawframe <- left_join(rawframe, SFILENR_help)
remove(SFILENR_help)
rawframe$NTDID_rel <- rawframe$NTDID - rawframe$NTDID_rel+1

rawframe$viol_id <- NA
for (i in 1:nrow(rawframe)) {
  if ((rawframe$DMW[i]>rawframe$DTO[i])|(rawframe$DMW[i]<rawframe$DTU[i]))
    rawframe$viol_id[i] <- rawframe$NTDID_rel[i] 
}


```

##2.3 Explore Data and Visualization

Routines:  
Create sub dataframes of numeric and non numeric variables  
Do basic data transformation and sorting  
```{r, echo = FALSE}

#create a sub dataframe of numeric varialbes
df_num <- as.data.frame (rawframe [ , sapply(rawframe,is.numeric)])
print (paste("Dimension of dataframe of numeric variables (columns)", dim(df_num)[2]))

#create a sub dataframe of non numeric varialbes
df_not_num <- as.data.frame (rawframe [ , !sapply(rawframe,is.numeric)])
print (paste("Dimension of dataframe of not-numeric variables (columns)", dim(df_not_num)[2], ":"))
cat (names(df_not_num), "\n")

```

### 2.3.1 Boxplots and Histograms of all numerical variables

This section shows boxplots, histograms and the summary statistics of all numerical variables as well as related comments and descriptions which are extracted from the data control file.

```{r, echo = FALSE}
if (printpdf) pdf(outputfile)
if (scatterplot) plot (df_num) # scatter plot
plot_num (df_num, datadesc)
if (printpdf) dev.off()    # reset device to screen plot 
```

Explore a single numerical variable - data specific - and detect patterns:
* peaks at 10x iterm
* counts
* 3 most common values
```{r, echo = FALSE}
# mini feature engineering CATE
above_thresh_df <- df_num$DMW[(df_num$DMW>df_num$DTO)] - df_num$DTO[(df_num$DMW>df_num$DTO)] %>% as.data.frame( )
names(above_thresh_df) <- "above_thresh"
below_thresh_df <- df_num$DTU[(df_num$DMW<df_num$DTU)] - df_num$DMW[(df_num$DMW<df_num$DTU)] %>% as.data.frame( )
names(below_thresh_df) <- "below_thresh"

# Limitiation of counts on y axis as well as outliers on x axis
ggplot(data = above_thresh_df) +
  geom_histogram(mapping = aes(x = above_thresh), binwidth = 50000, na.rm = TRUE) +
  coord_cartesian(xlim = c(0, 11000000), ylim = c(0, 100)) +
  labs(x = "above_thresh")

ggplot(data = above_thresh_df) +
  geom_histogram(mapping = aes(x = above_thresh), binwidth = 1000, na.rm = TRUE) +
  coord_cartesian(xlim = c(0, 22000), ylim = c(0, 10)) +
  labs(x = "above_thresh")

# use "group by"" and "summarize" allways together
c_items <- above_thresh_df %>%
  group_by(above_thresh) %>%
  summarise(count = n()) %>%
  print()

#print ("3 most common value")
c_items <- (sort(table(above_thresh_df$above_thresh), decreasing = TRUE)) %>%
     as.data.frame()
c_items$perc <- c_items$Freq/sum(c_items$Freq)*100
print(c_items[1:3,])

# Limitiation of counts on y axis as well as outliers on x axis
ggplot(data = below_thresh_df) +
  geom_histogram(mapping = aes(x = below_thresh), binwidth = 5000, na.rm = TRUE) +
  coord_cartesian(xlim = c(0, 300000), ylim = c(0, 100)) +
  labs(x = "below_thresh")

# Limitiation of counts on y axis as well as outliers on x axis
ggplot(data = below_thresh_df) +
  geom_histogram(mapping = aes(x = below_thresh), binwidth = 10, na.rm = TRUE) +
  coord_cartesian(xlim = c(0, 500), ylim = c(0, 100)) +
  labs(x = "below_thresh")

# use "group by"" and "summarize" allways together
c_items <- below_thresh_df %>%
  group_by(below_thresh) %>%
  summarise(count = n()) %>%
  print()

#print ("3 most common value")
c_items <- (sort(table(below_thresh_df$below_thresh), decreasing = TRUE)) %>%
     as.data.frame()
c_items$perc <- c_items$Freq/sum(c_items$Freq)*100
print(c_items[1:3,])

```


### 2.3.2 Exploration of all non numerical variables

```{r, echo = FALSE}
summary_non_num (df_not_num, datadesc)
```

## 2.4 Verify data quality

### 2.4.1 check missing values

```{r}
j <- 1 #j is rawframe index, i is datadesc index
for(i in 1:nrow(datadesc)){  
  if (datadesc$`Clean Data Frame`[i] !='exclude') {
    cat(paste(names(rawframe[j]), "\t  # of NA:", colSums(is.na(rawframe[j])), 
              "  in %", round(colSums(is.na(rawframe[j])/nrow(rawframe)), 3)*100), "\n")
    datadesc$`% of na values`[i] <- round(colSums(is.na(rawframe[j]))/nrow(rawframe), 3)*100
    j <- j+1
  }  
}    
#write.csv2(datadesc$`% of na values`, file = "na_%.csv")
writexl::write_xlsx(datadesc, path = paste0(rel_fpath, filename, '_data_control.xlsx'))

```


### 2.4.2 check collinearity


```{r}
# produce correlation matrix
check_collinearity (df_num)
```

## 2.5 Pivot Section Board view - DF MC specific

Generation of FID / board related view:
- overall count of single measurements per board
- time(s) of passing measurement cycle, first/last pass
- time(s) of failing measurement cycle, first/last fail
- nr. of threshold violations


```{r}
# grouping by SID, showing pass and failure times with count of violations
count_messw <- rawframe %>% group_by(SID) %>% summarize(count=n(), SARTIKELNR=unique(SARTIKELNR)) #timediff=sum(DTINSERT-DTDATUM>100000), 3 boards mit zeitdiff
count_messw_pass <- rawframe %>% filter(SERGEBNIS=='PASS') %>% group_by(SID) %>% 
  summarize(count_pass=n(), time_pass=list(as.character(unique(DTDATUM))),
            first_pass=min(DTDATUM), last_pass=max(DTDATUM)
            )
count_messw_fail <- rawframe %>% filter(SERGEBNIS=='FAIL') %>% group_by(SID) %>% 
  summarize(count_fail=n(), time_fail=list(as.character(unique(DTDATUM))),
            first_fail=min(DTDATUM), last_fail=max(DTDATUM),
            limit_viol=sum((DMW>DTO)|(DMW<DTU)))
count_messw <- count_messw %>% full_join (count_messw_pass) %>% full_join (count_messw_fail)
# remove last_.. time when only one occurence
count_messw$last_pass[count_messw$first_pass==count_messw$last_pass] <- NA
count_messw$last_fail[count_messw$first_fail==count_messw$last_fail] <- NA
head(count_messw)
```

## 2.6 Pivot Section Measurement cycle view - SFILENAME

Generation of measurement cycle/SFILENAME related view:
- overall count of single measurements per board
- time of passing measurement cycle
- time of failing measurement cycle
- nr. of threshold violations per cycle

```{r}
SFILENR_table <- rawframe %>% group_by(SFILENAME) %>% summarize(count=n(), SARTIKELNR=unique(SARTIKELNR), SID=unique(SID), NTDIDS = NTDID[1])
SFILENR_table <- select(SFILENR_table, SARTIKELNR, SID, everything())

SFILENR_table_pass <- rawframe %>% filter(SERGEBNIS=='PASS') %>% group_by(SFILENAME) %>% 
  summarize(time_pass=(unique(DTDATUM)))

SFILENR_table_fail <- rawframe %>% filter(SERGEBNIS=='FAIL') %>% group_by(SFILENAME) %>% 
  summarize(time_fail=(unique(DTDATUM)), limit_viol=sum((DMW>DTO)|(DMW<DTU)))

SFILENR_table <- SFILENR_table %>% full_join (SFILENR_table_pass) %>% full_join (SFILENR_table_fail)
remove(SFILENR_table_pass, SFILENR_table_fail)
head(SFILENR_table)

# Verteilung der Abbrüche bzw. pass
hist(SFILENR_table$count, breaks = 100)
ggplot(data = SFILENR_table, mapping = aes(x = count)) +  
         geom_histogram(binwidth = 10) +
#         coord_cartesian(xlim = c(0, 1000)) +
         facet_wrap(~ SARTIKELNR, ncol = 2, scales = "free")
hist(SFILENR_table$count, breaks = 100)

```

## 2.6 Combine Q-Daten

several joins of Q Data, pseudo error and label qualification from Q Data. Label qualifiation means those measurements where ICT measurement is before a repair entry.

```{r}
count_messw_full <- count_messw %>% full_join (q_daten, by = c("SID" = "FID")) 
count_messwinner <- count_messw %>% inner_join (q_daten, by = c("SID" = "FID")) 
count_messw_left <- count_messw %>% left_join (q_daten, by = c("SID" = "FID")) 
# fail vs repair time
count_messwinner$fail_repair <- 0
for (i in 1:nrow(count_messwinner)) {
  count_messwinner$fail_repair[i] <- paste(count_messwinner$time_fail[[i]][[1]],count_messwinner$DATUM[i])
}
# true label flag
count_messwinner$label <- count_messwinner$DATUM > count_messwinner$first_fail
count_messw_full$label <- count_messw_full$DATUM > count_messw_full$first_fail
count_messw_left$label <- count_messw_left$DATUM > count_messw_left$first_fail
cat("FID / boards of ICT measurements which have an entry in Q Data: ", nrow(count_messwinner), "\n")  
cat("FID / boards where repair is after ICT measurement (error detected in ICT and afterwards repaired): ", sum(count_messw_left$label, na.rm = TRUE), "\n")  

count_messw_full$pseudo <- !is.na(count_messw_full$first_fail) & !is.na(count_messw_full$first_pass)  # 231 pseudo errors
count_messw_left$pseudo <- !is.na(count_messw_left$first_fail) & !is.na(count_messw_left$first_pass)  # 231 pseudo errors
cat("Nr. of pseudo errors detected: ", sum(count_messw_left$pseudo), "\n")  

# remove empty columns after left_join
count_messw_left <- select(count_messw_left, -c(STATUS, BEFUND_FBG, ZNR_BE, BE_KURZTEXT, BKZ_BE, PRUEFER1))
count_messw_left <- select(count_messw_left, -"STATUS")


```

pure FID fails in Q Data?
```{r}
cat("distribution of fails in Q Data over variants/pruefstufen\n")  
pure_fail_Q_variant <- q_daten %>% group_by(OBERSTUFE) %>% summarize(count=n())
print(pure_fail_Q_variant)
pure_fail_Q_pruefst <- q_daten %>% group_by(PRUEFSTUFE) %>% summarize(count=n())
print(pure_fail_Q_pruefst)
```

pure FID fails in ICT measurement Data?
```{r}
# only fails: 6490 - most of them from Q data  (6475 - 32 innerjoin + 47 fail related ICT)
# sum(is.na(count_messw_full$first_pass))

cat("pure fails related to FID in ICT data: ",
  sum(is.na(count_messw$first_pass))
, "\n")
pure_fail_ICT <- count_messw %>% filter(is.na(first_pass)) %>% group_by(SARTIKELNR) %>% summarize(count=n())
cat("distribution of fails in Q Data over variants\n") 
print(pure_fail_ICT)

# provide pure fail flag
count_messw_left$pure_fail <- is.na(count_messw_left$first_pass)   
```

## 2.6 Unsuccessful measurement cycles distribution

Following two charts show the distribution of unsuccessful measurement cycles (SFILENR) over all variants and specific per variant

```{r}
hist(count_messw_full$count_fail, breaks = 100)

ggplot(data = count_messw_full, mapping = aes(x = count_fail)) +  
         geom_histogram(binwidth = 10) +
         coord_cartesian(xlim = c(0, 1000)) +
         facet_wrap(~ SARTIKELNR, ncol = 2, scales = "free_y")
```         
         

```{r}
# list in DF problem!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
print("...save board data frame")
outputcsv <- "./output/board.csv"
write.table(select(count_messw, -(time_pass:time_fail)),       # write resulting data into CSV file with tabstops
            file=outputcsv,
            sep=",", quote=FALSE, row.names=FALSE, dec=".") 
```

## 2.7 Trend failures - DF MC specific

```{r}

messw_fail_trend <- rawframe %>% filter(SERGEBNIS=='FAIL') %>% group_by(SFILENAME) %>% summarize(count_fail=n(),
                                                                                           time_fail=unique(DTDATUM))

ggplot(data = messw_fail_trend, mapping = aes(x = time_fail)) +
         geom_histogram(binwidth = 10000)

hist(messw_fail_trend$time_fail, 100)

```

## 2.8 Pivot Section Component view - DF MC specific

```{r}

board_view <- rawframe %>% group_by(SMMNR) %>% summarize(count=n(), limit_viol=sum((DMW>DTO)|(DMW<DTU)))

spec_bauteil <- rawframe %>% filter(SMMNR=='10.40.235_R701_235') %>% arrange(DTINSERT)
plot(spec_bauteil$DTINSERT, spec_bauteil$DMW, type ="l")

```

## 3.1 Transformation of variables

```{r}
datadesc <- read_datadesc(data_control_file)
df_clean <- transformation(rawframe, datadesc)

#create new sub dataframes for numeric and non numeric variables
df_num <- as.data.frame (df_clean [ , sapply(df_clean,is.numeric)])
df_not_num <- as.data.frame (df_clean [ , !sapply(df_clean,is.numeric)])
```

## 3.2 Reduction of variables, visualization and saving of clean data

NOT RELEVANT in DF MC case - already done above
```{r}
datadesc <- read_datadesc(data_control_file)
# exclude not relevant variables according to Data Description entry in column Clean Data Frame
df_clean <- rawframe[ ,datadesc$`Clean Data Frame`!="exclude"]  

#create new sub dataframes for numeric and non numeric variables
df_num <- as.data.frame (df_clean [ , sapply(df_clean,is.numeric)])
df_not_num <- as.data.frame (df_clean [ , !sapply(df_clean,is.numeric)])

```

```{r}
# =================================================
# again perform data exploration as above in chapter 2
                           # Boxplots and Histograms for numerical variables
if (printpdf) pdf(outputfile)
if (scatterplot) plot (df_num) # scatter plot
plot_num (df_num, datadesc)
if (printpdf) dev.off()    # reset device to screen plot 

summary_non_num (df_not_num, datadesc)    # Exploration of non numerical variables
```

```{r}
# specific line for DF MC
df_clean <- rawframe
print("...save clean data frame")
if (shortnames==T) outputcsv <- "./output/clean_4_modeling_with_factors.csv"
write.table(df_clean,       # write resulting data into CSV file with tabstops
            file=outputcsv,
            sep=",", quote=FALSE, row.names=FALSE, dec=".") 
```

## 3.3 Create dummy variables, visualization and saving of clean data

```{r}
datadesc <- read_datadesc(data_control_file)
df_clean <- create_dummy(df_clean, datadesc)

#create new sub dataframes for numeric and non numeric variables
df_num <- as.data.frame (df_clean [ , sapply(df_clean,is.numeric)])
df_not_num <- as.data.frame (df_clean [ , !sapply(df_clean,is.numeric)])
```

```{r}
# =================================================
# Save clean data frame with dummy variables
# =================================================
print("...save clean data frame")
if (shortnames==T) outputcsv <- "./output/clean_4_modeling_with_dummies.csv"
write.table(df_clean,       # write resulting data into CSV file with tabstops
            file=outputcsv, 
            sep=",", quote=FALSE, row.names=FALSE, dec=".") 
```

