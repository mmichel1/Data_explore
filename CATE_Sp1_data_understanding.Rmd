---
title: "Project: CATE"
subtitle: "Sprint 1: Data Understanding"
date: 2018-08-06  
output:
  word_document: default
  pdf_document: default
  html_document:
  code_folding: hide
  df_print: paged
---

# Data Understanding Topics

Overall dataset check if matching requirements (completeness, volumes, labels, accessability)

* Summary statistics (incl. mean, median, variations, ...)
* Five numbers summary by boxplots (numerical data)
* Distribution by bar charts and histograms
* Categories reduction
* Missing values and outliers
* Subgroups, patterns and trends
* Correlations (numerical variables)

#1. Setup Environment
Provide filenames, ~type and environment variables.
Source data exploration routines.

```{r, echo=FALSE, results='hide'}
#  Libraries 
library(readxl)
library(tidyverse)
library(hexbin)
# Parameters 
rel_fpath  <- "./data/"    # relative directory where original data is stored
filename ='A5E01283425_30062016_25072016' # file name of the original data 
filename2 ='A5E02758387_01062016_25072016' # file name of the original data
filename3 ='A5E02758387_11072016_15082016' # file name of the original data
filename4 ='A5E31281377_15062016_11072016_BGmitwenigenFehlern' # file name of the original data
filename5 ='A5E32692783_25072016_15082016' # file name of the original data
filename6 ='BD_CIB_DAC-A5E33212840_01062016_01072016' # file name of the original data
filename7 ='CIB_DAC-A5E33212840_01072016_25072016' # file name of the original data

endung ='.csv'            # file extension of the original data
rel_fpath_output <- "./data/" # relative directory where outputs are stored
outputfile <- "./output/data_exploration.pdf"  # writes plots and clean data frame to outputfile
outputcsv  <- "./output/clean_4_modelling_with_R.csv"

Read_Fresh_from_File <- F  # Set to TRUE for first run to fill var rawframe
                           # clean dat frame, set to FALSE for initial data understanding
options(scipen=999)        # suppress exponential form of print output format
printpdf <- FALSE          # if printout in PDF desired
shortnames <- TRUE         # if T change to short variable names is desired
scatterplot <- FALSE       # it T do scatterplot
basic_tranform <- T        # do basic feature transformations
# Sources 
source(file = "Functions_data_exploration.R")
```

#2. D a t a   U n d e r s t a n d i n g
  
##2.1 Collect Initial Data

Routines:  
Read from data sources from "rel_fpath"!  
Read description and configuration file from "rel_fpath"!  
Save data as RDS file format 

###2.1.1 Collect ICT measurement Data

Read 7 ICT measurement files.

A5E01283425_30062016_25072016.csv
A5E02758387_01062016_25072016.csv
A5E02758387_11072016_15082016.csv
A5E31281377_15062016_11072016_BGmitwenigenFehlern.csv
A5E32692783_25072016_15082016.csv
BD_CIB_DAC-A5E33212840_01062016_01072016.csv
CIB_DAC-A5E33212840_01072016_25072016.csv

```{r, echo = FALSE}
# ====================== R e a d   d a t a ============== alternative
library(writexl)
if (Read_Fresh_from_File)  {
  print("reading file.... ")
  # --- read excel ----
  if (endung == ".xlsx")   {
     rawframe <- read_xlsx (path = paste0(rel_fpath, filename, endung ), guess_max=100000)
     warnings()
  } else
  {  #--- read other formats ---
  rawframe <- read_data_csv(data_file_name = paste0(rel_fpath, filename, endung))
  rawframe2 <- read_data_csv(data_file_name = paste0(rel_fpath, filename2, endung))
  rawframe3 <- read_data_csv(data_file_name = paste0(rel_fpath, filename3, endung))
  rawframe4 <- read_data_csv(data_file_name = paste0(rel_fpath, filename4, endung))
  rawframe5 <- read_data_csv(data_file_name = paste0(rel_fpath, filename5, endung))
  rawframe6 <- read_data_csv(data_file_name = paste0(rel_fpath, filename6, endung))
  rawframe7 <- read_data_csv(data_file_name = paste0(rel_fpath, filename7, endung))
  }

  saveRDS(rawframe, file = paste(rel_fpath_output , filename, ".rData"))
  saveRDS(rawframe2, file = paste(rel_fpath_output , filename2, ".rData2"))
  saveRDS(rawframe3, file = paste(rel_fpath_output , filename3, ".rData3"))
  saveRDS(rawframe4, file = paste(rel_fpath_output , filename4, ".rData4"))
  saveRDS(rawframe5, file = paste(rel_fpath_output , filename5, ".rData5"))
  saveRDS(rawframe6, file = paste(rel_fpath_output , filename6, ".rData6"))
  saveRDS(rawframe7, file = paste(rel_fpath_output , filename7, ".rData7"))
  print("...Data saved in RData file")
} else { # Read_Fresh_from_File gleich FALSE
  rawframe <- readRDS(file = paste(rel_fpath_output , filename, ".rData"))
  rawframe2 <- readRDS(file = paste(rel_fpath_output , filename2, ".rData2"))
  rawframe3 <- readRDS(file = paste(rel_fpath_output , filename3, ".rData3"))
  rawframe4 <- readRDS(file = paste(rel_fpath_output , filename4, ".rData4"))
  rawframe5 <- readRDS(file = paste(rel_fpath_output , filename5, ".rData5"))
  rawframe6 <- readRDS(file = paste(rel_fpath_output , filename6, ".rData6"))
  rawframe7 <- readRDS(file = paste(rel_fpath_output , filename7, ".rData7"))
}
#--- create / read data control file ---
if (file.exists(path = paste0(rel_fpath, filename, '_data_control.xlsx')))
  data_control_file <-  paste0(rel_fpath, filename, '_data_control.xlsx') else
    data_control_file <- paste0(rel_fpath, 'data_control_template.xlsx')
datadesc <- read_datadesc(data_control_file)
  
# initial exclusion of not relevant variables according to Data Description entry in column Clean Data Frame
rawframe <- rawframe[ ,datadesc$`Clean Data Frame`!="exclude"]  
rawframe2 <- rawframe2[ ,datadesc$`Clean Data Frame`!="exclude"]  
rawframe3 <- rawframe3[ ,datadesc$`Clean Data Frame`!="exclude"]  
rawframe4 <- rawframe4[ ,datadesc$`Clean Data Frame`!="exclude"]  
rawframe5 <- rawframe5[ ,datadesc$`Clean Data Frame`!="exclude"]  
rawframe6 <- rawframe6[ ,datadesc$`Clean Data Frame`!="exclude"]  
rawframe7 <- rawframe7[ ,datadesc$`Clean Data Frame`!="exclude"]  

# write control file if not present
if (!file.exists(path = paste0(rel_fpath, filename, '_data_control.xlsx')))  {
  datadesc[1:length(names(rawframe)), 1] <-  names(rawframe)
  writexl::write_xlsx(datadesc, path = paste0(rel_fpath, filename, '_data_control.xlsx'))
}

```

Generation of data snapshot for generating Tableau input data.
Pulls each 20.000 single measurements from each ICT file and stores it in csv file
```{r, echo = FALSE}
rawframesnap <- rawframe[1:20000, ] %>% rbind(rawframe2[1:20000, ]) %>% rbind(rawframe3[1:20000, ]) %>% rbind(rawframe4[1:20000, ]) %>% rbind(rawframe5[1:20000, ]) %>% rbind(rawframe6[1:20000, ]) %>% rbind(rawframe7[1:20000, ]) 

#sorting - eases further exploration
rawframesnap <- rawframesnap %>% arrange(SPLATZNR, DTDATUM, NORDER)
#df_num$`Total Customer Price (EUR)` <- log(df_num$`Total Customer Price (EUR)`)
rawframesnap <- rawframesnap[rawframesnap$SEINHEIT != 'OE' ,]
write.table(rawframesnap,       # write resulting data into CSV file with tabstops
            file=paste0(rel_fpath, "raw_data_snap", endung),
            sep=";", quote=FALSE, row.names=FALSE, dec=",") 

```

Remove duplicate measurements, generate one combined rawframe for ICT measurements:
```{r, echo = FALSE}
# check for double measurements - 258 cycles of two A5E02758387 - files
cat("check for double measurements - duplicated measurement cycles (SFILENR) of two A5E02758387 - files: ", 
sum(duplicated(c(unique(rawframe$SFILENAME), unique(rawframe2$SFILENAME), unique(rawframe3$SFILENAME), unique(rawframe4$SFILENAME), unique(rawframe5$SFILENAME), unique(rawframe6$SFILENAME), unique(rawframe7$SFILENAME)))) 
, "\n")
#sum(duplicated(c(rawframe2$NTDID, rawframe3$NTDID))) # 198380

#combine to one huge frame
rawframe <- rawframe %>% rbind(rawframe2) %>% rbind(rawframe3) %>% rbind(rawframe4) %>% rbind(rawframe5) %>% rbind(rawframe6) %>% rbind(rawframe7) 
remove(rawframe2, rawframe3, rawframe4, rawframe5, rawframe6, rawframe7)
# remove duplicated measurements
cat("removed duplicated single measurements (NTDID): ", 
sum(duplicated(rawframe$NTDID)) # 198380
, "\n")
rawframe <- rawframe[duplicated(rawframe$NTDID)=="FALSE", ]
```
###2.1.2 Collect Q Data

```{r, echo = FALSE, results='hold'}
q_daten <- read_delim("data/DPMI_Fehler_alle_alle_201606_bis_201608_31.07.2018_adapt.csv", 
    ";", escape_double = FALSE, col_types = cols(DATUM = col_datetime(format = "%d.%m.%Y %H:%M")),
    locale = locale(encoding = "ISO-8859-1"), 
    trim_ws = TRUE)
# remove Prüfstufe Gerät, subsequently delete empty columns
#q_daten <- q_daten[q_daten$PRUEFSTUFE != 'G', ]
#q_daten <- q_daten[, 1:15]

# remove duplicates in Q Data: 
cat("remove duplicates in Q Data: ", sum(duplicated(q_daten)), "rows \n")  
q_daten <- q_daten[duplicated(q_daten)=="FALSE", ]

# remove double entries of FID - first approach - of course information is lost - future: provide at least removed marker or move up as additional features
q_daten <- q_daten[duplicated(q_daten$FID)=="FALSE", ]
cat(nrow(q_daten), "rows remaining\n")  

```


##2.2 Describe Data   

##2.3 Explore Data and Visualization

Routines:  
Create sub dataframes of numeric and non numeric variables  
Do basic data transformation and sorting  
```{r, echo = FALSE}
#sorting - eases further exploration
rawframe <- rawframe %>% arrange(SPLATZNR, DTDATUM, NORDER)

#basic transformations - datenspezifisch!
if (basic_tranform) {
  #df_num$`Total Customer Price (EUR)` <- log(df_num$`Total Customer Price (EUR)`)
  rawframe <- rawframe[rawframe$SEINHEIT != 'OE' ,]
}

cat("In total", nrow(rawframe), "single measurement points (NTDID) after removing Soll-Istwerte lines\n\n")  

#create a sub dataframe of numeric varialbes
df_num <- as.data.frame (rawframe [ , sapply(rawframe,is.numeric)])
print (paste("Dimension of dataframe of numeric variables (columns)", dim(df_num)[2], ":"))
cat (names(df_num), "\n")

#create a sub dataframe of non numeric varialbes
df_not_num <- as.data.frame (rawframe [ , !sapply(rawframe,is.numeric)])
print (paste("Dimension of dataframe of not-numeric variables (columns)", dim(df_not_num)[2], ":"))
cat (names(df_not_num), "\n")
```

### 2.3.1 Boxplots and Histograms of all numerical variables

This section shows boxplots, histograms and the summary statistics of all numerical variables as well as related comments and descriptions which are extracted from the data control file.

```{r, echo = FALSE}
if (printpdf) pdf(outputfile)
if (scatterplot) plot (df_num) # scatter plot
plot_num (df_num, datadesc)
if (printpdf) dev.off()    # reset device to screen plot 
```

### 2.3.2 Exploration of all non numerical variables

```{r, echo = FALSE}
summary_non_num (df_not_num, datadesc)
```

## 2.4 Verify data quality

### 2.4.1 Check missing values

```{r, echo = FALSE}
j <- 1 #j is rawframe index, i is datadesc index
for(i in 1:nrow(datadesc)){  
  if (datadesc$`Clean Data Frame`[i] !='exclude') {
    cat(paste(names(rawframe[j]), "\t  # of NA:", colSums(is.na(rawframe[j])), 
              "  in %", round(colSums(is.na(rawframe[j])/nrow(rawframe)), 3)*100), "\n")
    datadesc$`% of na values`[i] <- round(colSums(is.na(rawframe[j]))/nrow(rawframe), 3)*100
    j <- j+1
  }  
}    
#write.csv2(datadesc$`% of na values`, file = "na_%.csv")
writexl::write_xlsx(datadesc, path = paste0(rel_fpath, filename, '_data_control.xlsx'))

```


### 2.4.2 Check collinearity

Correlation between input variables in ICT measurements are displayed:
```{r, echo = FALSE}
# produce correlation matrix
check_collinearity (df_num)
```

## 2.5 Pivot Section - view per FID / Board

Generation of FID / board related view:
- overall count of single measurements per board
- time(s) of passing measurement cycle, first/last pass
- time(s) of failing measurement cycle, first/last fail
- nr. of threshold violations


```{r, results='hold'}
# grouping by SID, showing pass and failure times with count of violations
count_messw <- rawframe %>% group_by(SID) %>% summarize(count=n(), SARTIKELNR=unique(SARTIKELNR)) #timediff=sum(DTINSERT-DTDATUM>100000), 3 boards mit zeitdiff
count_messw_pass <- rawframe %>% filter(SERGEBNIS=='PASS') %>% group_by(SID) %>% 
  summarize(count_pass=n(), time_pass=list(as.character(unique(DTDATUM))),
            first_pass=min(DTDATUM), last_pass=max(DTDATUM)
            )
count_messw_fail <- rawframe %>% filter(SERGEBNIS=='FAIL') %>% group_by(SID) %>% 
  summarize(count_fail=n(), time_fail=list(as.character(unique(DTDATUM))),
            first_fail=min(DTDATUM), last_fail=max(DTDATUM),
            limit_viol=sum((DMW>DTO)|(DMW<DTU)))
count_messw <- count_messw %>% full_join (count_messw_pass) %>% full_join (count_messw_fail)
# remove last_.. time when only one time occurence
count_messw$last_pass[count_messw$first_pass==count_messw$last_pass] <- NA
count_messw$last_fail[count_messw$first_fail==count_messw$last_fail] <- NA
head(count_messw)
```

## 2.6 Combine Q-Daten

inner and left join of Q Data to identify common FID. Pseudo error and label qualification are attached to joined data. Label qualifiation means those measurements where ICT measurement is before a repair entry.

```{r, results='hold'}
count_messwinner <- count_messw %>% inner_join (q_daten, by = c("SID" = "FID")) 
count_messw_left <- count_messw %>% left_join (q_daten, by = c("SID" = "FID")) 
# fail vs repair time
count_messwinner$fail_repair <- 0
for (i in 1:nrow(count_messwinner)) {
  count_messwinner$fail_repair[i] <- paste(count_messwinner$time_fail[[i]][[1]],count_messwinner$DATUM[i])
}
# true label flag
count_messwinner$label <- count_messwinner$DATUM > count_messwinner$first_fail
count_messw_left$label <- count_messw_left$DATUM > count_messw_left$first_fail
cat("FID / boards of ICT measurements which have an entry in Q Data: ", nrow(count_messwinner), "\n")  
cat("FID / boards where repair is after ICT measurement (error detected in ICT and afterwards repaired): ", sum(count_messw_left$label, na.rm = TRUE), "\n")  

count_messw_left$pseudo <- !is.na(count_messw_left$first_fail) & !is.na(count_messw_left$first_pass)  # 231 pseudo errors
cat("Nr. of pseudo errors detected: ", sum(count_messw_left$pseudo), "\n")  

```

How many FID - pure fails are in Q Data?
```{r, results='hold'}
cat("distribution of fails in Q Data over variants/pruefstufen\n")  
pure_fail_Q_variant <- q_daten %>% group_by(OBERSTUFE) %>% summarize(count=n())
print(pure_fail_Q_variant)
pure_fail_Q_pruefst <- q_daten %>% group_by(PRUEFSTUFE) %>% summarize(count=n())
print(pure_fail_Q_pruefst)
```

How are the FID - pure fails distributed over the variants in ICT measurement Data?
```{r, results='hold'}
# only fails: 6490 - most of them from Q data  (6475 + 15 additional in ICT measurements (47 fail in ICT - 32 also in Q Data))
# sum(is.na(count_messw_full$first_pass))

cat("pure fails related to FID in ICT data: ",
  sum(is.na(count_messw$first_pass))
, "\n")
pure_fail_ICT <- count_messw %>% filter(is.na(first_pass)) %>% group_by(SARTIKELNR) %>% summarize(count=n())
cat("distribution of fails in Q Data over variants\n") 
print(pure_fail_ICT)

# provide pure fail flag
count_messw_left$pure_fail <- is.na(count_messw_left$first_pass)   
```

## 2.6 Unsuccessful measurement cycles distribution

Following two charts show the distribution of unsuccessful measurement cycles (SFILENR) over all variants and specific per variant.

```{r, results='hold'}
hist(count_messw_left$count_fail, breaks = 100)

ggplot(data = count_messw_left, mapping = aes(x = count_fail)) +  
         geom_histogram(binwidth = 10, na.rm=TRUE) +
         coord_cartesian(xlim = c(0, 1000)) +
         facet_wrap(~ SARTIKELNR, ncol = 2, scales = "free_y")
```         
         

```{r, echo=FALSE, results='hide'}
print("...save board data frame")
outputcsv <- "./output/board.csv"
write.table(select(count_messw, -(time_pass:time_fail)),       # write resulting data into CSV file with tabstops without embedded date lists
            file=outputcsv,
            sep=",", quote=FALSE, row.names=FALSE, dec=".") 
```

## 2.7 Trend of failures over the time

Following chart shows the measurement cycle failure trend over time:
```{r, results='hold'}
messw_fail_trend <- rawframe %>% filter(SERGEBNIS=='FAIL') %>% group_by(SFILENAME) %>% summarize(count_fail=n(),
                                                                                           time_fail=unique(DTDATUM))

ggplot(data = messw_fail_trend, mapping = aes(x = time_fail)) +
         geom_histogram(binwidth = 10000)
```

